{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the weather like today?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the price of gold today?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want to book a flight ticket.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you tell me the current exchange rate?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I cook pho?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>Enumerate your range of capabilities.</td>\n",
       "      <td>Ask Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Describe what kind of tasks you can handle.</td>\n",
       "      <td>Ask Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>Detail the functions you excel in.</td>\n",
       "      <td>Ask Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>Explain your range of assistance.</td>\n",
       "      <td>Ask Features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Describe what you can help</td>\n",
       "      <td>Ask Features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         messages        intent\n",
       "0                  What's the weather like today?      Negative\n",
       "1                 What's the price of gold today?      Negative\n",
       "2                 I want to book a flight ticket.      Negative\n",
       "3      Can you tell me the current exchange rate?      Negative\n",
       "4                              How do I cook pho?      Negative\n",
       "...                                           ...           ...\n",
       "1637        Enumerate your range of capabilities.  Ask Features\n",
       "1638  Describe what kind of tasks you can handle.  Ask Features\n",
       "1639           Detail the functions you excel in.  Ask Features\n",
       "1640            Explain your range of assistance.  Ask Features\n",
       "1641                   Describe what you can help  Ask Features\n",
       "\n",
       "[1642 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_intent = pd.read_csv(\"../assistant/data/common_intents.csv\")\n",
    "train_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1642 entries, 0 to 1641\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   messages  1642 non-null   object\n",
      " 1   intent    1642 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_intent.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative             532\n",
      "Greet                206\n",
      "Description          199\n",
      "Course Search        196\n",
      "Open Landing Page    184\n",
      "Ask Features         125\n",
      "Bot Challenge        100\n",
      "Ask Name             100\n",
      "Name: intent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Xem số lượng mỗi intent\n",
    "intent_counts = train_intent['intent'].value_counts()\n",
    "print(intent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you help me find my lost phone?</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open the landing page for Business Process Ana...</td>\n",
       "      <td>Open Landing Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Search for courses in history.</td>\n",
       "      <td>Course Search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the system requirements for using the...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, quick chat?</td>\n",
       "      <td>Greet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>Hey, can we discuss this?</td>\n",
       "      <td>Greet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Display the course overview for Business Proce...</td>\n",
       "      <td>Open Landing Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>Hi, how’s it going today?</td>\n",
       "      <td>Greet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>Hey, got a question for you</td>\n",
       "      <td>Greet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Take me to the course overview for Negotiation...</td>\n",
       "      <td>Open Landing Page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               messages             intent\n",
       "0                   Can you help me find my lost phone?           Negative\n",
       "1     Open the landing page for Business Process Ana...  Open Landing Page\n",
       "2                        Search for courses in history.      Course Search\n",
       "3     What are the system requirements for using the...           Negative\n",
       "4                                       Hi, quick chat?              Greet\n",
       "...                                                 ...                ...\n",
       "1637                          Hey, can we discuss this?              Greet\n",
       "1638  Display the course overview for Business Proce...  Open Landing Page\n",
       "1639                          Hi, how’s it going today?              Greet\n",
       "1640                        Hey, got a question for you              Greet\n",
       "1641  Take me to the course overview for Negotiation...  Open Landing Page\n",
       "\n",
       "[1642 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_intent = train_intent.sample(frac=1).reset_index(drop=True)\n",
    "train_intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rasa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, RobertaModel, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# define RoBERTa model\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "roberta_model = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = {\n",
    "    'Description': 0,\n",
    "    'Course Search': 1,\n",
    "    'Open Landing Page': 2,\n",
    "    'Negative': 3,\n",
    "    'Bot Challenge': 4,\n",
    "    'Greet': 5,\n",
    "    'Ask Features': 6,\n",
    "    'Ask Name': 7\n",
    "}\n",
    "\n",
    "for item in train_intent[\"intent\"]:\n",
    "    if item not in intents:\n",
    "        print(f\"intent value '{item}' not found in intents dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(train_intent, test_size=0.2, random_state=42)\n",
    "\n",
    "def prepare_input_data(data):\n",
    "    encoded_data = roberta_tokenizer(data[\"messages\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "train_inputs = prepare_input_data(train_data)\n",
    "test_inputs = prepare_input_data(test_data)\n",
    "\n",
    "train_labels = torch.tensor([intents[item] for item in train_data[\"intent\"]])\n",
    "test_labels = torch.tensor([intents[item] for item in test_data[\"intent\"]])\n",
    "\n",
    "print(len(train_inputs['input_ids']))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Device: mps\n"
     ]
    }
   ],
   "source": [
    "class IntentClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(IntentClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.relu1(pooled_output)\n",
    "        x = self.relu2(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "    \n",
    "num_classes = 8\n",
    "model = IntentClassifier(roberta_model, num_classes)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Selected Device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader for training data\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 1.5189712856497084\n",
      "Epoch 2/5, Average Loss: 0.27898008473927066\n",
      "Epoch 3/5, Average Loss: 0.07417297638243153\n",
      "Epoch 4/5, Average Loss: 0.03810286858961696\n",
      "Epoch 5/5, Average Loss: 0.0256066271325662\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_data_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {total_loss / len(train_data_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.18%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Move input data to the device\n",
    "    test_input_ids = test_inputs['input_ids'].to(device)\n",
    "    test_attention_mask = test_inputs['attention_mask'].to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(test_input_ids, test_attention_mask)\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    # Move predicted labels back to CPU for accuracy calculation\n",
    "    predicted_labels = predicted_labels.cpu()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/common_intents/intent_tokenizer/tokenizer_config.json',\n",
       " 'models/common_intents/intent_tokenizer/special_tokens_map.json',\n",
       " 'models/common_intents/intent_tokenizer/vocab.json',\n",
       " 'models/common_intents/intent_tokenizer/merges.txt',\n",
       " 'models/common_intents/intent_tokenizer/added_tokens.json',\n",
       " 'models/common_intents/intent_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model state_dict\n",
    "torch.save(model.state_dict(), 'models/common_intents/intent_model.pt')\n",
    "\n",
    "# Save tokenizer\n",
    "roberta_tokenizer.save_pretrained('models/common_intents/intent_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted whisper intent for the sentence is: Greet\n"
     ]
    }
   ],
   "source": [
    "def predict_intents(sentence, model, tokenizer, tense_labels, device):\n",
    "    # Move model and tokenizer to the specified device\n",
    "    model = model.to(device)\n",
    "    tokenizer = tokenizer\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    encoded_sentence = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits = model(encoded_sentence['input_ids'], encoded_sentence['attention_mask'])\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Get the predicted tense label\n",
    "    predicted_intent = [k for k, v in tense_labels.items() if v == predicted_label][0]\n",
    "    \n",
    "    return predicted_intent\n",
    "\n",
    "# Specify the device (e.g., 'cuda', 'mps' for GPU or 'cpu' for CPU)\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "sentence_to_predict = \"\"\"\n",
    "hello\n",
    "\"\"\"\n",
    "predicted_intent = predict_intents(sentence_to_predict, model, roberta_tokenizer, intents, device)\n",
    "print(f\"The predicted whisper intent for the sentence is: {predicted_intent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
