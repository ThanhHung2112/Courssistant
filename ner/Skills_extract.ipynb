{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanhHung2112/Indeed_crawler/blob/main/Skills_extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EERxpSpUO1YW",
        "outputId": "4c44abf0-8158-4fdc-e564-e90e2e697b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/rasa/bin/python: No module named spacy\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ErgLdMl8GKCH"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "tags = [\n",
        "\"Business_skill\"\n",
        "\"ComputerScience_skill\"\n",
        "\"DataScience_skill\"\n",
        "\"Health_skill\"\n",
        "\"PhysicalScienceAndengineering_skill\"\n",
        "\"SocialSciences_skill\"\n",
        "\"Artsandhumannities_skill\"\n",
        "\"Informationtechnology_skill\"\n",
        "\"languagelearning_skill\"\n",
        "\"PersonalDevelopment_skill\"\n",
        "\"Mathandlogic_skill\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nHArGO-JyZkv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import json\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings (optional, use with caution)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"spacy\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"tensorflow\")\n",
        "\n",
        "# Load training data from JSON file\n",
        "def load_data_from_json(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            data = json.load(file)\n",
        "        return data\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON in file {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add the NER component to the pipeline\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "# Add the labels (in this case, just \"SKILL\")\n",
        "ner.add_label(\"skill\")\n",
        "\n",
        "# Disable other pipeline components for training efficiency\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# Specify the path to your JSON file\n",
        "json_file_path = \"300_minn.json\"\n",
        "\n",
        "# Load training data from JSON file\n",
        "training_data = load_data_from_json(json_file_path)\n",
        "\n",
        "if training_data:\n",
        "    # Remove duplicate entities based on start and end positions\n",
        "    cleaned_training_data = []\n",
        "    seen_entities = set()\n",
        "\n",
        "    for entry in training_data:\n",
        "        labels_list = entry.get(\"label\", [])\n",
        "\n",
        "        # Ensure that labels is a list of dictionaries\n",
        "        if isinstance(labels_list, str):\n",
        "            labels_list = [{\"text\": labels_list, \"start\": -1, \"end\": -1, \"labels\": [\"skill\"]}]\n",
        "        elif not isinstance(labels_list, list):\n",
        "            continue  # Skip entries without a valid label list\n",
        "\n",
        "        cleaned_labels_list = []\n",
        "        for label in labels_list:\n",
        "            start = label.get(\"start\", -1)\n",
        "            end = label.get(\"end\", -1)\n",
        "            label_text = label.get(\"labels\", \"\")\n",
        "\n",
        "            # Ensure unique start and end positions\n",
        "            if (start, end) not in seen_entities:\n",
        "                cleaned_labels_list.append({\"text\": label_text, \"start\": start, \"end\": end, \"labels\": [\"skill\"]})\n",
        "                seen_entities.add((start, end))\n",
        "\n",
        "        if cleaned_labels_list:\n",
        "            cleaned_training_data.append({\"text\": entry.get(\"text\", \"\"), \"label\": cleaned_labels_list})\n",
        "\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        # Initialize the training\n",
        "        nlp.begin_training()\n",
        "\n",
        "        # Iterate through the cleaned training data for multiple epochs\n",
        "        for epoch in range(1000):\n",
        "            # Shuffle the cleaned training data\n",
        "            random.shuffle(cleaned_training_data)\n",
        "\n",
        "            # Create batches of cleaned training data\n",
        "            for entry in cleaned_training_data:\n",
        "                text = entry.get(\"text\", \"\")\n",
        "                labels_list = entry.get(\"label\", [])\n",
        "\n",
        "                # Process annotations and extract entities\n",
        "                entities = []\n",
        "                for label in labels_list:\n",
        "                    start = label.get(\"start\", -1)\n",
        "                    end = label.get(\"end\", -1)\n",
        "                    label_text = label.get(\"labels\", \"\")\n",
        "                    entities.append((start, end, label_text))\n",
        "\n",
        "                # Create a spaCy Example\n",
        "                example = Example.from_dict(nlp.make_doc(text), {\"entities\": entities})\n",
        "\n",
        "                # Update the model with iterating each example\n",
        "                nlp.update([example], drop=0.5)\n",
        "\n",
        "    # Save the trained model to disk /content/drive/MyDrive/NER/\n",
        "    nlp.to_disk(\"skills_ner_model\")\n",
        "else:\n",
        "    print(\"Failed to load training data from the JSON file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55B-gHqDm0xC",
        "outputId": "08ae5e0e-38b5-4cbe-f9d3-ccf27d2d8a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text: I am skilled in Python and Java programming.\n",
            "Entities: []\n",
            "\n",
            "Input Text: My experience includes using TensorFlow for machine learning.\n",
            "Entities: []\n",
            "\n",
            "Input Text: I have hands-on experience with MongoDB and MySQL.\n",
            "Entities: []\n",
            "\n",
            "Input Text: write full length feature film script course write complete feature length screenplay film television serious drama romantic comedy anything learn break creative process component discover structured process allow produce polished pitch ready script end course complete project increase confidence idea ability feel prepared pitch first script get start next course design tap creativity base active learn actual learning take place within activity write learn link trailer course view trailer please copy paste link browser https vimeocom b b dc learner review love approach professor wheeler take towards course point easy follow informative would definitely recommend anyone interested take screenplay writing course course curriculum simple adopt professional writer room process write post work peer review share feedback peer revise work feedback receive peer real world feel professional writer room yet prior experience writer require proponent experiential learn active learning lecture short sometimes two minute long point design step step process essential success script writer guide show write firmly believe way become writer write write write learner review would like thank course instructor amazing course need get start mention prior script writing experience require begin basic word processor week two choose download free scriptwriting software celtx trelby may choose purchase final draft industry standard continue use word processor script format learner review writer concern regard protection original work coursera privacy policy protect learner ip indeed sole owner work\n",
            "Entities: []\n",
            "\n",
            "Input Text: Build machine learning\n",
            "Entities: []\n",
            "\n",
            "Input Text: use java and sql to management database\n",
            "Entities: []\n",
            "\n",
            "Input Text: \n",
            "    As Technical Account Manager you will support our internal and external clients in online marketing campaigns configuration. We are working on our own proprietary solution that is the main point of clientâ€™s Marketing Technology Stack, integrating data from various services and delivering this data to external providers.\n",
            "\n",
            "Tasks\n",
            "\n",
            "Analyzing client websites to make sure they have the data needed for online marketing campaigns.\n",
            "Setting up, running, checking, and turning off various services for clients.\n",
            "Solving issues with these services.\n",
            "Working with our developer teams to handle reported problems, configure services, improve existing solutions, and brainstorm new ones.\n",
            "Checking problem reports and passing them to the right teams with initial analysis results.\n",
            "Looking at services from external vendors that we haven't used yet when we need them.\n",
            "Completing tasks with clear documentation for reference in the future.\n",
            "Opportunity to become the go-to person for a particular area of our knowledge base and manage internal team documentation.\n",
            "Actively participating in team meetings where we all discuss team matters (Governance Meeting).\n",
            "Requirements\n",
            "\n",
            "You should know about internet browsers (understand what happens when you enter a website URL and hit \"Enter\").\n",
            "You should be comfortable using Developer tools in browsers (able to analyze network traffic and inspect data layer - like JavaScript variables and DOM elements variables).\n",
            "You should be familiar with Online Marketing tools, such as:\n",
            "Principles of Tag management systems (like Google Tag Manager, which is a must, and others like Tealium or Commanders Act)\n",
            "Analytics tools like Google Analytics\n",
            "Online Marketing platforms, like Google Ads, Facebook Advertising, and others (Criteo, Google Marketing Platform, Microsoft Advertising, etc.)\n",
            "Consent Management Platforms (CMP) like Usercentrics, Klaro, OneTrust, Didomi\n",
            "You should have some knowledge of SQL (to write basic queries for database data retrieval).\n",
            "You should have some understanding of JavaScript (or a willingness to learn) to handle monitoring code implementation (tracking data, processing, using variables from DOM or URL).\n",
            "You should be knowledgeable about online privacy topics, especially regarding tracking codes and Privacy Enhanced Technologies in various browsers.\n",
            "Fluency in English is a must.\n",
            "You should be able to document your work so that you or anyone else can pick up where you left off and retain valuable information for future reference (knowledge capture).\n",
            "Understanding processes related to IT service management (like ITIL) is a plus.\n",
            "You should be a good team player, adhering to mutually agreed-upon rules and be able to communicate on technical topics with both technical and non-technical individuals.\n",
            "Knowledge of the German language is an added advantage.\n",
            "You'll help maintain the team and company's positive image.\n",
            "You should understand and support the team's vision, to which you will be contributing.\n",
            "Benefits\n",
            "\n",
            "Work in a global team.\n",
            "remote work first company.\n",
            "Competitive pay.\n",
            "Enjoy perks like a MultiSport card and private health coverage.\n",
            "Grow professionally with learning opportunities.\n",
            "Join a friendly, energetic team with a laid-back work environment\n",
            "    \n",
            "Entities: []\n",
            "\n",
            "Input Text: Client should have strong problem solving skills, and good at both reading and speaking English\n",
            "Entities: []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model from disk\n",
        "loaded_nlp = spacy.load(\"skills_ner_model\")\n",
        "\n",
        "# Test the loaded model with some example texts\n",
        "test_texts = [\n",
        "    \"I am skilled in Python and Java programming.\",\n",
        "    \"My experience includes using TensorFlow for machine learning.\",\n",
        "    \"I have hands-on experience with MongoDB and MySQL.\",\n",
        "    \"write full length feature film script course write complete feature length screenplay film television serious drama romantic comedy anything learn break creative process component discover structured process allow produce polished pitch ready script end course complete project increase confidence idea ability feel prepared pitch first script get start next course design tap creativity base active learn actual learning take place within activity write learn link trailer course view trailer please copy paste link browser https vimeocom b b dc learner review love approach professor wheeler take towards course point easy follow informative would definitely recommend anyone interested take screenplay writing course course curriculum simple adopt professional writer room process write post work peer review share feedback peer revise work feedback receive peer real world feel professional writer room yet prior experience writer require proponent experiential learn active learning lecture short sometimes two minute long point design step step process essential success script writer guide show write firmly believe way become writer write write write learner review would like thank course instructor amazing course need get start mention prior script writing experience require begin basic word processor week two choose download free scriptwriting software celtx trelby may choose purchase final draft industry standard continue use word processor script format learner review writer concern regard protection original work coursera privacy policy protect learner ip indeed sole owner work\",\n",
        "    \"Build machine learning\",\n",
        "    \"use java and sql to management database\",\n",
        "    \"\"\"\n",
        "    As Technical Account Manager you will support our internal and external clients in online marketing campaigns configuration. We are working on our own proprietary solution that is the main point of clientâ€™s Marketing Technology Stack, integrating data from various services and delivering this data to external providers.\n",
        "\n",
        "Tasks\n",
        "\n",
        "Analyzing client websites to make sure they have the data needed for online marketing campaigns.\n",
        "Setting up, running, checking, and turning off various services for clients.\n",
        "Solving issues with these services.\n",
        "Working with our developer teams to handle reported problems, configure services, improve existing solutions, and brainstorm new ones.\n",
        "Checking problem reports and passing them to the right teams with initial analysis results.\n",
        "Looking at services from external vendors that we haven't used yet when we need them.\n",
        "Completing tasks with clear documentation for reference in the future.\n",
        "Opportunity to become the go-to person for a particular area of our knowledge base and manage internal team documentation.\n",
        "Actively participating in team meetings where we all discuss team matters (Governance Meeting).\n",
        "Requirements\n",
        "\n",
        "You should know about internet browsers (understand what happens when you enter a website URL and hit \"Enter\").\n",
        "You should be comfortable using Developer tools in browsers (able to analyze network traffic and inspect data layer - like JavaScript variables and DOM elements variables).\n",
        "You should be familiar with Online Marketing tools, such as:\n",
        "Principles of Tag management systems (like Google Tag Manager, which is a must, and others like Tealium or Commanders Act)\n",
        "Analytics tools like Google Analytics\n",
        "Online Marketing platforms, like Google Ads, Facebook Advertising, and others (Criteo, Google Marketing Platform, Microsoft Advertising, etc.)\n",
        "Consent Management Platforms (CMP) like Usercentrics, Klaro, OneTrust, Didomi\n",
        "You should have some knowledge of SQL (to write basic queries for database data retrieval).\n",
        "You should have some understanding of JavaScript (or a willingness to learn) to handle monitoring code implementation (tracking data, processing, using variables from DOM or URL).\n",
        "You should be knowledgeable about online privacy topics, especially regarding tracking codes and Privacy Enhanced Technologies in various browsers.\n",
        "Fluency in English is a must.\n",
        "You should be able to document your work so that you or anyone else can pick up where you left off and retain valuable information for future reference (knowledge capture).\n",
        "Understanding processes related to IT service management (like ITIL) is a plus.\n",
        "You should be a good team player, adhering to mutually agreed-upon rules and be able to communicate on technical topics with both technical and non-technical individuals.\n",
        "Knowledge of the German language is an added advantage.\n",
        "You'll help maintain the team and company's positive image.\n",
        "You should understand and support the team's vision, to which you will be contributing.\n",
        "Benefits\n",
        "\n",
        "Work in a global team.\n",
        "remote work first company.\n",
        "Competitive pay.\n",
        "Enjoy perks like a MultiSport card and private health coverage.\n",
        "Grow professionally with learning opportunities.\n",
        "Join a friendly, energetic team with a laid-back work environment\n",
        "    \"\"\",\n",
        "    \"Client should have strong problem solving skills, and good at both reading and speaking English\"\n",
        "\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    doc = loaded_nlp(text)\n",
        "    print(\"Input Text:\", text)\n",
        "    print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JptOl5mGBxnD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/rasa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/opt/anaconda3/envs/rasa/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Ivo/emscad-skill-extraction\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Ivo/emscad-skill-extraction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading full_matcher ...\n",
            "loading abv_matcher ...\n",
            "loading full_uni_matcher ...\n",
            "loading low_form_matcher ...\n",
            "loading token_matcher ...\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# load default skills data base\n",
        "from skillNer.general_params import SKILL_DB\n",
        "# import skill extractor\n",
        "from skillNer.skill_extractor_class import SkillExtractor\n",
        "\n",
        "# init params of skill extractor\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "# init skill extractor\n",
        "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
        "\n",
        "# extract skills from job_description\n",
        "job_description = \"\"\"\n",
        "You are a Python developer with a solid experience in web development\n",
        "and can manage projects. You quickly adapt to new environments\n",
        "and speak fluently English and French\n",
        "\"\"\"\n",
        "\n",
        "annotations = skill_extractor.annotate(job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'you are a python developer with a solid experience in web development and can manage projects you quickly adapt to new environments and speak fluently english and french',\n",
              " 'results': {'full_matches': [{'skill_id': 'KS122Z36QK3N5097B5JH',\n",
              "    'doc_node_value': 'web development',\n",
              "    'score': 1,\n",
              "    'doc_node_id': [10, 11]}],\n",
              "  'ngram_scored': [{'skill_id': 'KS125LS6N7WP4S6SFTCK',\n",
              "    'doc_node_id': [3],\n",
              "    'doc_node_value': 'python',\n",
              "    'type': 'fullUni',\n",
              "    'score': 1,\n",
              "    'len': 1},\n",
              "   {'skill_id': 'KS1267F6MSPN366LX7ST',\n",
              "    'doc_node_id': [14, 15],\n",
              "    'doc_node_value': 'manage projects',\n",
              "    'type': 'lowSurf',\n",
              "    'score': 2,\n",
              "    'len': 2},\n",
              "   {'skill_id': 'KS120626HMWCXJWJC7VK',\n",
              "    'doc_node_id': [18],\n",
              "    'doc_node_value': 'adapt',\n",
              "    'type': 'lowSurf',\n",
              "    'score': 0.5245310068130493,\n",
              "    'len': 1},\n",
              "   {'skill_id': 'KS123K75YYK8VGH90NCS',\n",
              "    'doc_node_id': [25],\n",
              "    'doc_node_value': 'english',\n",
              "    'type': 'lowSurf',\n",
              "    'score': 1,\n",
              "    'len': 1},\n",
              "   {'skill_id': 'KS1243976G466GV63ZBY',\n",
              "    'doc_node_id': [27],\n",
              "    'doc_node_value': 'french',\n",
              "    'type': 'lowSurf',\n",
              "    'score': 1,\n",
              "    'len': 1}]}}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPGJdbiBlAxcoukQQq/rlzF",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1KYwcuQBmhA4OIkM3z9LJ5CyWMRcN7gCd",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
